Processing Raw Brook Trout Data
========================================================

### Daniel J. Hocking
### 11 February 2014

Set working directory and load packages
```{r working directory and libraries, warning = FALSE, message = FALSE, echo = TRUE, results = 'hide'}

setwd('/Users/Dan/Documents/Research/Stream_Climate_Change/Brook_Trout/Data/')

library(dplyr)
library(data.table)
library(reshape2)
library(ggplot2)
```

CT
------------------------------------------------

The `Yoichiro_data_08212012 v2.xlsx` would not save as a csv or txt file from excel, so saved as a `.xls` file and opened in **LibreOffice**, which was able to convert it to a csv. Use `fread` function from the `data.table` package to read in large files much quicker. Thankfully, the commas entered in the data did not cause a problem with importing the csv file appropriately, likely because it recognized it as part of the string since the entire column was characters. This occus in both the "Landmark" and "Common Name" columns. I did have to do a find `"` and replace with nothing to get the data to parse correctly.

```{r results = 'hide'}
setwd('/Users/Dan/Documents/Research/Stream_Climate_Change/Brook_Trout_Data/')

ct.raw <- fread("CT_Raw/CT_Raw.csv")
str(ct.raw)
summary(ct.raw)
head(ct.raw, 30)
```

Add unique key and state for resorting, error checking, and combining with other datasets. Replace column names with something more sensible, concise, and lacking spaces and special characters. Use `setnames()` rather than `names() <-` because setnames doesn't create a copy of the dataframe in the process, therefore saves memory and time.

```{r results = 'hide'}
ct.raw$state.key <- seq(from = 1, to = length(ct.raw[ , 1]))
ct.raw$state <- "CT"
names(ct.raw)
setnames(ct.raw, c("date1", "run.samplebysite", "stream.name", "proximity", "landmark", "basin", "municipality", "official", "lat", "lon", "metadata.samplybysite", "expr1011", "pass", "sample.length", "shock.time", "stream.width", "species", "tl.cm", "wild", "count", "sci.name", "common.name", "site", "state.key", "state"))
names(ct.raw)
head(ct.raw, 30)
```

### Clean Data
Replace sample.length of 0 with NA, shock.time of 0 with NA, tl.cm of -99 and 9999 with NA, count -99 with NA. Check some really high values.

```{r results = 'hide'}
summary(ct.raw)
ct.raw$count[which(ct.raw$count < 0)] <- NA
ct.raw$shock.time[which(ct.raw$shock.time == 0)] <- NA
ct.raw$stream.width[which(ct.raw$stream.width == 0)] <- NA
ct.raw$stream.width[which(ct.raw$stream.width > 50)] <- NA
ct.raw$sample.length[which(ct.raw$sample.length == 0)] <- NA
ct.raw$tl.cm[which(ct.raw$tl.cm == -99)] <- NA
ct.raw$tl.cm[which(ct.raw$tl.cm == 9999)] <- NA

summary(ct.raw)

hist(ct.raw$sample.length) # consider cutting over 600 (break) or 1000m because methods could differ signicantly
hist(ct.raw$count)
hist(ct.raw$shock.time)
hist(ct.raw$stream.width)
hist(ct.raw$tl.cm[which(ct.raw$sci.name == "Salvelinus fontinalis")])
summary(ct.raw$tl.cm[which(ct.raw$sci.name == "Salvelinus fontinalis")])

ct.raw[which(ct.raw$tl.cm > 30 & ct.raw$sci.name == "Salvelinus fontinalis"), c(sci.name, tl.cm)] # find mis-entered length data for brook trout
ct.raw$tl.cm[which(ct.raw$tl.cm == 112 & ct.raw$sci.name == "Salvelinus fontinalis")] <- NA

plot(ct.raw$shock.time, ct.raw$count)
plot(ct.raw$sample.length, ct.raw$count)
plot(ct.raw$shock.time, ct.raw$sample.length) # large values match so are likely not typos
ggplot(data = ct.raw, aes(sample.length, count)) + geom_point()

ct.raw$date <- as.Date(ct.raw$date1, "%m/%d/%Y")

ct.raw$year <- as.numeric(format(ct.raw$date, format = "%Y"))
ct.raw$month <- as.numeric(format(ct.raw$date, format = "%m")) 


library(ggmap)
map.center <- geocode("Hartford, CT")
baseMap <- qmap(c(lon=map.center$lon, lat=map.center$lat), source="google", zoom=7)
baseMap + geom_point(aes(x=lon, y=lat), 
                                #size=(count)),
                                #color=factor(pres)), 
                            data=ct.raw[which(ct.raw$sci.name == "Salvelinus fontinalis"), ])
  #ggtitle( as.character(y)))
```

Add calculated fields (turn length into stage - at least for brook trout >80 mm in August = adult) - or do when combine all data

What to do about timing of surveys affecting detection of YOY, include stage at all?


Separate fish data for combining with other datasets



Collapse to unique site-visit


MA
------------------------------------------------

```{r results = 'hide'}
setwd('/Users/Dan/Documents/Research/Stream_Climate_Change/Brook_Trout/Data/MA_Raw/')

ma.raw <- read.table('Mass_fish_data_EBTJV_7-15-13.csv', sep = ",", header = TRUE)

str(ma.raw)
head(ma.raw[ , -c(14,15)], 30)


```

Any data not summarized yet? Talk to Yoichiro and contact state of mass biologist to get all fish data if possible, not summarized



ME
------------------------------------------------

Use the `read.dbf` function in the `foreign` package to read in data from the shapefile. 

```{r results = 'hide'}
library(foreign)

setwd('/Users/Dan/Documents/Research/Stream_Climate_Change/Brook_Trout/Data/ME_Raw/')
me.raw <- read.dbf("Data_Request_EBTJV_Maine.dbf")

str(me.raw)
summary(me.raw)
head(me.raw, 30)

levels(as.factor(me.raw$RUNNUM))
levels(as.factor(me.raw$LIFE_STAGE))

me.raw[which(me.raw$SPP == "BKT"), c("BEGDATE", "GEAR_TYPE", "LIFE_STAGE", "ABUNDANCE")]

me.raw2 <- read.dbf("DATA_REQ.dbf")
str(me.raw2)
summary(me.raw2)
head(me.raw2, 20)

dim(me.raw)
dim(me.raw2)

length(me.raw2[which(me.raw2$RUNNUM > 1), ]$RUNNUM)

me.raw2[which(me.raw2$RUNNUM > 1 & me.raw2$SPP == "BKT"), c("TOPUTMX", "TOPUTMY", "LOCATIONID", "RUNNUM", "SPP", "LIFE_STAGE", "BEGDATE", "ABUNDANCE")]

me.raw2[which(me.raw2$RUNNUM > 1 & me.raw2$SPP == "BKT"), c("LOCATIONID", "RUNNUM", "SPP", "LIFE_STAGE", "BEGDATE", "ABUNDANCE", "GEAR_TYPE")] # appear to be duplicate records!!!

me.raw2[c(3645, 3650), ]

me.raw2.unique <- unique(me.raw2) # remove duplicate records
dim(me.raw2.unique)

me.raw2.unique[which(me.raw2.unique$RUNNUM > 1 & me.raw2.unique$SPP == "BKT"), c("LOCATIONID", "RUNNUM", "SPP", "LIFE_STAGE", "BEGDATE", "ABUNDANCE")] # much better

dim(me.raw2.unique)
dim(me.raw2.unique[which(me.raw2.unique$RUNNUM == 2 & me.raw2.unique$SPP == "BKT"), ])
# Only ~1% of site-visits had at least 2 passes

me.raw2.unique[which(me.raw2.unique$LIFE_STAGE == "Adults/Juveniles"), ]


```

**ISSUES**
1. The UTM coordinates are strange and will need conversion.
2. RUNNUM = pass?
3. Unify NA, Unknown, unknown, etc.
  * Adults/Juveniles
  * Sublegal
  * Legal
  * YOY/Juveniles/Adults
4. Currently no sample length
5. SPP merge with species codes file
6. Two .dbf files are almost identical but have slightly different mean abundances and NA (NA stored as 0 in one?) - Use DATA_REQ.dbf
7. Duplicate records!!!



NH
------------------------------------------------

I removed `"`, `'`, `;`, `:`, and `,` in the data for importing into R. Also replaced `n/a` and `<100` with `NA`. I also removed spaces in the headings. Otherwise, I left the data alone so all the processing could be done transparently and reproducibly in R.

```{r results = 'hide'}
setwd('/Users/Dan/Documents/Research/Stream_Climate_Change/Brook_Trout/Data/NH_Raw/')

nh.raw <- fread("NH_data_Enumerated.csv", header = TRUE, sep = ",", na.strings = c("NA", "na", "N/A", "n/a", "", "<100")) # check warnings() to find where errors such as "<100" cause problems with numeric columns, use colClasses if needed
str(nh.raw)
summary(nh.raw)
head(nh.raw, 30)

nh.raw[1:20, ]
```

add primary key

```{r}
nh.raw$nh.key <- seq(1, length(nh.raw$LAT), by = 1)
```

Change remaining column names to be more R coding friendly

```{r results = 'hide'}
setnames(nh.raw, names(nh.raw), new = c('lat', 'lon', 'year', 'date.old', 'date.new', 'waterbody', 'sample.length', 'sample.area', 'bkt', 'bkt.hatchery', 'bt', 'bt.hatchery', 'rt', 'rt.hatchery', 'comments', 'nh.key'))

names(nh.raw)

```

Replace `NE` with 

```{r results = 'hide'}
nh.raw$bkt[which(nh.raw$bkt == "NE")] <- NA
nh.raw$bkt <- as.numeric(nh.raw$bkt)
class(nh.raw$bkt)
summary(nh.raw)
str(nh.raw)

nh.raw$bkt.hatchery[which(nh.raw$bkt.hatchery == "NE")] <- NA
nh.raw$bkt.hatchery <- as.numeric(nh.raw$bkt.hatchery)

nh.raw$bt[which(nh.raw$bt == "NE")] <- NA
nh.raw$bt <- as.numeric(nh.raw$bt)

nh.raw$bt.hatchery[which(nh.raw$bt.hatchery == "NE")] <- NA
nh.raw$bt.hatchery <- as.numeric(nh.raw$bt.hatchery)

nh.raw$rt[which(nh.raw$rt == "NE")] <- NA
nh.raw$rt <- as.numeric(nh.raw$rt)

nh.raw$rt.hatchery[which(nh.raw$rt.hatchery == "NE")] <- NA
nh.raw$rt.hatchery <- as.numeric(nh.raw$rt.hatchery)

summary(nh.raw)
```

Convert excel dates to R recognized dates

```{r results = 'hide'}
nh.raw$date <- as.Date(nh.raw$date.new, "%m/%d/%y")
str(nh.raw)
summary(nh.raw)
head(nh.raw, 20)
range(nh.raw$date, na.rm = TRUE) # 1983 - 2012
```

Create unique site ID and see how many sites are repetedly sampled

```{r}
nh.raw$site <- paste(nh.raw$lat, nh.raw$lon)

```



NY
------------------------------------------------

```{r results = 'hide'}
setwd('/Users/Dan/Documents/Research/Stream_Climate_Change/Brook_Trout/Data/NY_Raw/')

ny.raw <- fread("NY_BKT_Data.csv", header = TRUE, sep = ",", na.strings = c("NA", "na", "N/A", "n/a", ""))
str(ny.raw)
summary(ny.raw)
head(ny.raw, 30)

```








RI
------------------------------------------------



Southern
------------------------------------------------

















